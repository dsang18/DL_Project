{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary Imports\nimport cv2\nimport pathlib\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\n# View an image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport random\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:23:57.159056Z","iopub.execute_input":"2023-09-30T04:23:57.159504Z","iopub.status.idle":"2023-09-30T04:23:57.432026Z","shell.execute_reply.started":"2023-09-30T04:23:57.159471Z","shell.execute_reply":"2023-09-30T04:23:57.430742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path to Kaggle Input\npath = \"../input/indian-monuments-image-dataset/Indian-monuments/images\"\n# Walk through the directory and list number of files\nfor dirpath, dirnames, filenames in os.walk(path):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:23:57.435342Z","iopub.execute_input":"2023-09-30T04:23:57.435810Z","iopub.status.idle":"2023-09-30T04:24:00.333512Z","shell.execute_reply.started":"2023-09-30T04:23:57.435769Z","shell.execute_reply":"2023-09-30T04:24:00.332196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir =  path + \"/train/\"\ntest_dir = path + \"/test/\"\ntrain_dir","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.334977Z","iopub.execute_input":"2023-09-30T04:24:00.335335Z","iopub.status.idle":"2023-09-30T04:24:00.343681Z","shell.execute_reply.started":"2023-09-30T04:24:00.335278Z","shell.execute_reply":"2023-09-30T04:24:00.342557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get all the class names\ndata_dir = pathlib.Path(train_dir)\nclass_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\nclass_names","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.345165Z","iopub.execute_input":"2023-09-30T04:24:00.345746Z","iopub.status.idle":"2023-09-30T04:24:00.369359Z","shell.execute_reply.started":"2023-09-30T04:24:00.345703Z","shell.execute_reply":"2023-09-30T04:24:00.368176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.371975Z","iopub.execute_input":"2023-09-30T04:24:00.372466Z","iopub.status.idle":"2023-09-30T04:24:00.380894Z","shell.execute_reply.started":"2023-09-30T04:24:00.372434Z","shell.execute_reply":"2023-09-30T04:24:00.379182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n\n# Rescale the data and create data generator instances\ntrain_datagen = ImageDataGenerator(rescale=1/255.)\ntest_datagen = ImageDataGenerator(rescale=1/255.)\n\n# Load data in from directories and turn it into batches\ntrain_data = train_datagen.flow_from_directory(train_dir,\n                                               target_size=(224, 224, 3),\n                                               batch_size=32,\n                                               class_mode='categorical') \n\ntest_data = train_datagen.flow_from_directory(test_dir,\n                                              target_size=(224, 224, 3),\n                                              batch_size=32,\n                                              class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.382174Z","iopub.execute_input":"2023-09-30T04:24:00.382760Z","iopub.status.idle":"2023-09-30T04:24:00.675687Z","shell.execute_reply.started":"2023-09-30T04:24:00.382728Z","shell.execute_reply":"2023-09-30T04:24:00.674601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_10 = Sequential([\n  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n  MaxPool2D(),\n  Conv2D(10, 3, activation='relu'),\n  MaxPool2D(),\n  Flatten(),\n  Dense(24, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.677422Z","iopub.execute_input":"2023-09-30T04:24:00.677734Z","iopub.status.idle":"2023-09-30T04:24:00.760019Z","shell.execute_reply.started":"2023-09-30T04:24:00.677707Z","shell.execute_reply":"2023-09-30T04:24:00.758844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_10.compile(loss='categorical_crossentropy',\n#                  optimizer=tf.keras.optimizers.Adam(),\n#                  metrics=['accuracy'])\n\n# history_10 = model_10.fit(train_data,\n#                           epochs=5,\n#                           steps_per_epoch=len(train_data),\n#                           validation_data=test_data,\n#                           validation_steps=len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.761440Z","iopub.execute_input":"2023-09-30T04:24:00.762247Z","iopub.status.idle":"2023-09-30T04:24:00.766078Z","shell.execute_reply.started":"2023-09-30T04:24:00.762216Z","shell.execute_reply":"2023-09-30T04:24:00.765219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_loss_curves(history_10)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.767158Z","iopub.execute_input":"2023-09-30T04:24:00.767731Z","iopub.status.idle":"2023-09-30T04:24:00.782182Z","shell.execute_reply.started":"2023-09-30T04:24:00.767686Z","shell.execute_reply":"2023-09-30T04:24:00.781006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import DenseNet121\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\n\n# Load the dataset\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32)\n\n\n\n# Define the DenseNet model\ndensenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\n# Add a global average pooling layer\nx = train_data\nx = tf.keras.applications.densenet.preprocess_input(x)\nx = densenet(x)\nx = GlobalAveragePooling2D()(x)\n\n# Add a dense layer\npredictions = Dense(24, activation='softmax')\n\n# Define the model\nmodel = Sequential()\nmodel.add(densenet)\nmodel.add(predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit_generator(train_generator, epochs=10, validation_data=validation_generator)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:29:22.349554Z","iopub.execute_input":"2023-09-30T04:29:22.349943Z","iopub.status.idle":"2023-09-30T04:29:26.022927Z","shell.execute_reply.started":"2023-09-30T04:29:22.349917Z","shell.execute_reply":"2023-09-30T04:29:26.021672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\n\n\n# Load the EfficientNetB0 model.\nmodel = tf.keras.applications.EfficientNetB0(weights='imagenet')\n\n\n# Compile the model.\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model on your dataset.\nmodel = model_10.fit(train_data,\n                          epochs=5,\n                          steps_per_epoch=len(train_data),\n                          validation_data=test_data,\n                          validation_steps=len(test_data))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T04:24:00.832584Z","iopub.status.idle":"2023-09-30T04:24:00.832951Z","shell.execute_reply.started":"2023-09-30T04:24:00.832784Z","shell.execute_reply":"2023-09-30T04:24:00.832801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}